// src/app/api/ai/background-params/route.ts
/**
 * POST /api/ai/background-params
 * 
 * LLMìœ¼ë¡œ ë™ì  ë°°ê²½ íŒŒë¼ë¯¸í„° ìƒì„±
 */

import { NextRequest, NextResponse } from "next/server";
import { requireAuth, checkMockMode } from "@/lib/auth/session";
import { prepareLLMInput } from "@/lib/llm/prepareLLMInput";
import { generateOptimizedPrompt } from "@/lib/llm/optimizePrompt";
import { validateAndNormalizeResponse, type BackgroundParamsResponse } from "@/lib/llm/validateResponse";
import { getCachedResponse, setCachedResponse } from "@/lib/cache/llmCache";
import { getMockPreprocessingData, getMockMoodStream } from "@/lib/mock/mockData";
import OpenAI from "openai";

/**
 * OpenAI API í˜¸ì¶œ ë° ë°°ê²½ íŒŒë¼ë¯¸í„° ìƒì„±
 *
 * mode:
 * - "stream" (default): 10ê°œ ì„¸ê·¸ë¨¼íŠ¸ ì „ì²´ì— ëŒ€í•œ ë°°ê²½ íŒŒë¼ë¯¸í„° ìƒì„±
 * - "scent": í˜„ì¬ ì„¸ê·¸ë¨¼íŠ¸ì˜ í–¥ / ì•„ì´ì½˜ë§Œ ì¬ì¶”ì²œ
 * - "music": í˜„ì¬ ì„¸ê·¸ë¨¼íŠ¸ì˜ ìŒì•… / í’í–¥Â·í’ì†ë§Œ ì¬ì¶”ì²œ
 */
export async function POST(request: NextRequest) {
  try {
    // ì„¸ì…˜ í™•ì¸ (ì¸ì¦ í•„ìš”)
    const sessionOrError = await requireAuth();
    if (sessionOrError instanceof NextResponse) {
      return sessionOrError;
    }
    const session = sessionOrError;
    
    // ê´€ë¦¬ì ëª¨ë“œ í™•ì¸ (ë°ì´í„°ëŠ” ëª©ì—…ì´ì§€ë§Œ LLMì€ ì‹¤ì œ í˜¸ì¶œ)
    const isAdminMode = checkMockMode(session);
    if (isAdminMode) {
      console.log("[LLM API] ê´€ë¦¬ì ëª¨ë“œ: ë°ì´í„°ëŠ” ëª©ì—…ì´ì§€ë§Œ LLMì€ ì‹¤ì œ í˜¸ì¶œ");
    }

    const body = await request.json();
    const mode = (body.mode || "stream") as "stream" | "scent" | "music";
    const forceFresh = body.forceFresh === true;

    // ------------------------------
    // 1) ê³µí†µ: ì „ì²˜ë¦¬ / ë¬´ë“œìŠ¤íŠ¸ë¦¼ ë°ì´í„° ì¡°íšŒ
    // ê´€ë¦¬ì ëª¨ë“œì—¬ë„ ëª©ì—… ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ LLMì— ì‹¤ì œë¡œ ì „ë‹¬
    // ------------------------------
    
    // ê´€ë¦¬ì ëª¨ë“œì¸ ê²½ìš° ëª©ì—… ë°ì´í„° ì§ì ‘ ì‚¬ìš© (fetch ëŒ€ì‹ )
    let preprocessed, moodStream;
    
    if (isAdminMode) {
      console.log("[LLM API] ê´€ë¦¬ì ëª¨ë“œ: ëª©ì—… ë°ì´í„° ì§ì ‘ ì‚¬ìš©");
      preprocessed = getMockPreprocessingData();
      const mockMoodStream = getMockMoodStream();
      moodStream = {
        currentMood: mockMoodStream.currentMood,
        moodStream: mockMoodStream.segments,
        userDataCount: mockMoodStream.userDataCount,
      };
    } else {
      // ì¼ë°˜ ëª¨ë“œ: API í˜¸ì¶œ (ì„œë²„ ì‚¬ì´ë“œì—ì„œ ì¿ í‚¤ ì „ë‹¬)
      const requestHeaders = new Headers();
      const cookies = request.headers.get("cookie");
      if (cookies) {
        requestHeaders.set("cookie", cookies);
      }
      
      const [preprocessedRes, moodStreamRes] = await Promise.all([
        fetch(`${process.env.NEXT_PUBLIC_BASE_URL || "http://localhost:3000"}/api/preprocessing`, {
          headers: requestHeaders,
          credentials: "include",
        }),
        fetch(`${process.env.NEXT_PUBLIC_BASE_URL || "http://localhost:3000"}/api/moods/current`, {
          headers: requestHeaders,
          credentials: "include",
        }),
      ]);

      if (!preprocessedRes.ok || !moodStreamRes.ok) {
        // ì—ëŸ¬ ë°œìƒ ì‹œ ëª©ì—… ë°ì´í„°ë¡œ ëŒ€ì²´
        console.warn("[LLM API] API í˜¸ì¶œ ì‹¤íŒ¨, ëª©ì—… ë°ì´í„° ì‚¬ìš©");
        preprocessed = getMockPreprocessingData();
        const mockMoodStream = getMockMoodStream();
        moodStream = {
          currentMood: mockMoodStream.currentMood,
          moodStream: mockMoodStream.segments,
          userDataCount: mockMoodStream.userDataCount,
        };
      } else {
        preprocessed = await preprocessedRes.json();
        moodStream = await moodStreamRes.json();
      }
    }

    // ------------------------------
    // 2) mode ë³„ ë¶„ê¸°
    // ------------------------------

    // (A) ìŠ¤íŠ¸ë¦¼ ì „ì²´ìš©: ê¸°ì¡´ ë¡œì§ ìœ ì§€ (10ê°œ ì„¸ê·¸ë¨¼íŠ¸)
    if (mode === "stream") {
      const segments = body.segments;
      if (!segments || !Array.isArray(segments) || segments.length === 0) {
        // segmentsê°€ ì—†ìœ¼ë©´ ëª©ì—… ì‘ë‹µ ë°˜í™˜
        return NextResponse.json(getMockResponse());
      }

      // 10ê°œ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ë¡œ LLM Input ì¤€ë¹„ (ì²« ë²ˆì§¸ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ëŒ€í‘œë¡œ ì‚¬ìš©)
      const firstSegment = segments[0];

      const llmInput = await prepareLLMInput(
        preprocessed,
        {
          currentMood: {
            id: firstSegment.mood?.id || "",
            name: firstSegment.moodName || firstSegment.mood?.name || "",
            cluster: "0",
            music: {
              genre: firstSegment.musicGenre || firstSegment.music?.genre || "",
              title: firstSegment.music?.title || "",
            },
            scent: {
              type: firstSegment.scentType || firstSegment.scent?.type || "",
              name: firstSegment.scent?.name || "",
            },
            lighting: {
              color: firstSegment.lighting?.color || "#E6F3FF",
              rgb: firstSegment.lighting?.rgb || [230, 243, 255],
            },
          },
          userDataCount: moodStream.userDataCount || 0,
        },
        body.userPreferences
      );

      // ìºì‹œ í™•ì¸ (ë¹„ìš© ì ˆê°)
      // "stream" ëª¨ë“œì—ì„œëŠ” segmentIndexë¥¼ í¬í•¨í•˜ì§€ ì•ŠìŒ
      const cacheKey = {
        moodName: llmInput.moodName,
        musicGenre: llmInput.musicGenre,
        scentType: llmInput.scentType,
        timeOfDay: llmInput.timeOfDay || new Date().getHours(),
        season: llmInput.season || "Winter",
        stressIndex: preprocessed.recent_stress_index,
        segmentIndex: undefined, // stream ëª¨ë“œì—ì„œëŠ” undefined
      };

      // ëŒ€ì‹œë³´ë“œì—ì„œ ê°•ì œ ìƒˆë¡œê³ ì¹¨(forceFresh) ìš”ì²­ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ìºì‹œ ì‚¬ìš©
      if (!forceFresh) {
        const cachedResponse = getCachedResponse(cacheKey);
        if (cachedResponse) {
          console.log("[LLM Cache] Cache hit, returning cached response");
          return NextResponse.json({ ...cachedResponse, source: "cache" });
        }
      }

      // ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„± (í† í° ìµœì†Œí™”, 10ê°œ ì„¸ê·¸ë¨¼íŠ¸ ìš”ì•½ í¬í•¨)
      const prompt = generateOptimizedPrompt(llmInput, segments);

      // OpenAI API í‚¤ í™•ì¸
      const apiKey = process.env.OPENAI_API_KEY;
      if (!apiKey) {
        console.warn("OPENAI_API_KEY not found, using mock response");
        const mockResponse = { ...getMockResponse(), source: "mock-no-key" as const };
        setCachedResponse(cacheKey, mockResponse);
        return NextResponse.json(mockResponse);
      }

      const openai = new OpenAI({ apiKey });

      try {
        const completion = await openai.chat.completions.create({
          model: "gpt-4o-mini",
          messages: [
            { role: "system", content: "JSONë§Œ ì‘ë‹µ" },
            { role: "user", content: prompt },
          ],
          response_format: { type: "json_object" },
          temperature: 0.9, // ë‹¤ì–‘ì„± ì¦ê°€ (0.7 â†’ 0.9)
          max_tokens: 3000, // 10ê°œ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ìœ„í•œ ì¶©ë¶„í•œ í† í° (500 â†’ 3000)
        });

        const rawResponse = JSON.parse(completion.choices[0].message.content || "{}");
        
        // ===== LLM ì›ì‹œ ì‘ë‹µ ë¡œê¹… =====
        console.log("\n" + "=".repeat(80));
        console.log("ğŸ¨ [LLM API] Raw Response from OpenAI:");
        console.log("=".repeat(80));
        console.log(JSON.stringify(rawResponse, null, 2));
        console.log("=".repeat(80) + "\n");
        
        const validatedResponse = validateAndNormalizeResponse(rawResponse);
        
        // ===== ê²€ì¦ëœ ì‘ë‹µ ë¡œê¹… =====
        console.log("\n" + "=".repeat(80));
        console.log("âœ… [LLM API] Validated Response (10 segments):");
        console.log("=".repeat(80));
        if ('segments' in validatedResponse && Array.isArray(validatedResponse.segments)) {
          console.log(`Total segments: ${validatedResponse.segments.length}`);
          validatedResponse.segments.forEach((seg, idx) => {
            console.log(`\n--- Segment ${idx} ---`);
            console.log(`  moodAlias: "${seg.moodAlias}"`);
            console.log(`  musicSelection: "${seg.musicSelection}"`);
            console.log(`  moodColor: "${seg.moodColor}"`);
            console.log(`  backgroundIcon: { name: "${seg.backgroundIcon.name}", category: "${seg.backgroundIcon.category}" }`);
            console.log(`  backgroundWind: { direction: ${seg.backgroundWind.direction}, speed: ${seg.backgroundWind.speed} }`);
            console.log(`  animationSpeed: ${seg.animationSpeed}, iconOpacity: ${seg.iconOpacity}`);
          });
          
          // ì»¬ëŸ¬ ì¤‘ë³µ ì²´í¬
          const colors = validatedResponse.segments.map(s => s.moodColor.toLowerCase());
          const colorCounts = colors.reduce((acc, color) => {
            acc[color] = (acc[color] || 0) + 1;
            return acc;
          }, {} as Record<string, number>);
          const duplicates = Object.entries(colorCounts).filter(([_, count]) => count > 1);
          if (duplicates.length > 0) {
            console.log(`\nâš ï¸  Color duplicates found:`);
            duplicates.forEach(([color, count]) => {
              console.log(`  ${color}: ${count} times`);
            });
          } else {
            console.log(`\nâœ… All colors are unique!`);
          }
        } else {
          console.log("âš ï¸  Single segment response (not array):");
          console.log(JSON.stringify(validatedResponse, null, 2));
        }
        console.log("=".repeat(80) + "\n");
        
        setCachedResponse(cacheKey, validatedResponse);
        return NextResponse.json({ ...validatedResponse, source: "openai" });
      } catch (openaiError) {
        console.error("[LLM API] OpenAI API í˜¸ì¶œ ì‹¤íŒ¨:", openaiError);
        // OpenAI API ì‹¤íŒ¨ ì‹œ ëª©ì—… ì‘ë‹µ ë°˜í™˜
        const mockResponse = { ...getMockResponse(), source: "mock-openai-error" as const };
        setCachedResponse(cacheKey, mockResponse);
        return NextResponse.json(mockResponse);
      }
    }

    // (B) í–¥ ì „ìš©: í˜„ì¬ ì„¸ê·¸ë¨¼íŠ¸ì˜ í–¥ / ì•„ì´ì½˜ë§Œ ì¬ì¶”ì²œ
    if (mode === "scent") {
      const segment = body.segment;
      if (!segment) {
        return NextResponse.json(
          { error: "INVALID_INPUT", message: "segment is required for scent mode" },
          { status: 400 }
        );
      }

      const llmInput = await prepareLLMInput(
        preprocessed,
        {
          currentMood: {
            id: segment.mood?.id || "",
            name: segment.moodName || segment.mood?.name || "",
            cluster: "0",
            music: {
              genre: segment.musicGenre || segment.music?.genre || "",
              title: segment.music?.title || "",
            },
            scent: {
              type: segment.scentType || segment.scent?.type || "",
              name: segment.scent?.name || "",
            },
            lighting: {
              color: segment.lighting?.color || "#E6F3FF",
              rgb: segment.lighting?.rgb || [230, 243, 255],
            },
          },
          userDataCount: moodStream.userDataCount || 0,
        },
        body.userPreferences
      );

      // "scent" ëª¨ë“œ: í˜„ì¬ ì„¸ê·¸ë¨¼íŠ¸ ì¸ë±ìŠ¤ í¬í•¨
      // bodyì—ì„œ segmentIndexë¥¼ ì§ì ‘ ë°›ê±°ë‚˜, moodStreamì—ì„œ ì°¾ê¸°
      const segmentIndexFromBody = body.segmentIndex;
      const currentSegmentIndex = segmentIndexFromBody !== undefined 
        ? segmentIndexFromBody 
        : (moodStream.moodStream?.findIndex((s: { timestamp: number; duration: number }) => 
            s.timestamp === segment.timestamp && 
            s.duration === segment.duration
          ) ?? -1);
      const cacheKey = {
        moodName: llmInput.moodName,
        musicGenre: llmInput.musicGenre,
        scentType: llmInput.scentType,
        timeOfDay: llmInput.timeOfDay || new Date().getHours(),
        season: llmInput.season || "Winter",
        stressIndex: preprocessed.recent_stress_index,
        segmentIndex: currentSegmentIndex >= 0 ? currentSegmentIndex : undefined,
      };

      const cachedResponse = getCachedResponse(cacheKey);
      if (cachedResponse) {
        return NextResponse.json({ ...cachedResponse, source: "cache" });
      }

      const apiKey = process.env.OPENAI_API_KEY;
      if (!apiKey) {
        console.warn("OPENAI_API_KEY not found, returning minimal mock for scent");
        const mock: BackgroundParamsResponse = {
          moodAlias: "Calm Breeze",
          musicSelection: "Ambient Meditation",
          moodColor: "#E6F3FF",
          lighting: {
            brightness: 50,
            temperature: 4000,
          },
          backgroundIcon: { name: "FaLeaf", category: "nature" },
          backgroundWind: {
            direction: 180,
            speed: 5,
          },
          animationSpeed: 5,
          iconOpacity: 0.7,
        };
        setCachedResponse(cacheKey, mock);
        return NextResponse.json({ ...mock, source: "mock-no-key" });
      }

      const openai = new OpenAI({ apiKey });

      const prompt = `
      ë‹¹ì‹ ì€ í–¥ê¸°ì™€ ì‹œê°ì  ì•„ì´ì½˜ì„ ë§¤ì¹­í•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
      ì•„ë˜ ì •ë³´ë¥¼ ë³´ê³ , í˜„ì¬ ë¬´ë“œì™€ ê°ì •ì„ ì€ ìœ ì§€í•˜ë©´ì„œ ê°™ì€ ê³„ì—´ì´ê±°ë‚˜ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ëŠ” ìƒˆë¡œìš´ í–¥ íƒ€ì…ê³¼,
      ê·¸ í–¥ì— ì–´ìš¸ë¦¬ëŠ” React Icons ìŠ¤íƒ€ì¼ì˜ ì•„ì´ì½˜ì„ 1ê°œ ì¶”ì²œí•˜ì„¸ìš”.

      [ë¬´ë“œ]: ${llmInput.moodName}
      [ìŒì•… ì¥ë¥´]: ${llmInput.musicGenre}
      [í˜„ì¬ í–¥ íƒ€ì…]: ${llmInput.scentType}
      [ìŠ¤íŠ¸ë ˆìŠ¤]: í‰ê·  ${preprocessed.average_stress_index}, ìµœê·¼ ${preprocessed.recent_stress_index}
      [ìˆ˜ë©´]: ì ìˆ˜ ${preprocessed.latest_sleep_score}, ì‹œê°„ ${preprocessed.latest_sleep_duration}ë¶„

      ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
      {
        "scentType": "marine | citrus | woody | floral | ... (ì†Œë¬¸ì, snake_case)",
        "backgroundIcon": {
          "name": "FaWater",
          "category": "nature | weather | object | abstract"
        }
      }
      `;

      const completion = await openai.chat.completions.create({
        model: "gpt-4o-mini",
        messages: [
          { role: "system", content: "JSONë§Œ ì‘ë‹µ" },
          { role: "user", content: prompt },
        ],
        response_format: { type: "json_object" },
        temperature: 0.7,
        max_tokens: 200,
      });

      const raw = JSON.parse(completion.choices[0].message.content || "{}");
      
      // ê¸°ì¡´ ì„¸ê·¸ë¨¼íŠ¸ ê°’ìœ¼ë¡œ ì™„ì „í•œ BackgroundParamsResponse êµ¬ì„±
      const result: BackgroundParamsResponse = {
        moodAlias: segment.moodName || segment.mood?.name || "Calm Breeze",
        musicSelection: segment.music?.title || segment.musicTitle || "Ambient Meditation",
        moodColor: segment.lighting?.color || "#E6F3FF",
        lighting: {
          brightness: segment.lighting?.brightness || 50,
          temperature: segment.lighting?.temperature || 4000,
        },
        backgroundIcon: raw.backgroundIcon || { name: "FaLeaf", category: "nature" },
        backgroundWind: segment.backgroundWind || {
          direction: 180,
          speed: 5,
        },
        animationSpeed: segment.animationSpeed || 5,
        iconOpacity: segment.iconOpacity || 0.7,
      };
      
      setCachedResponse(cacheKey, result);
      return NextResponse.json({ ...result, source: "openai" });
    }

    // (C) ìŒì•… ì „ìš©: í˜„ì¬ ì„¸ê·¸ë¨¼íŠ¸ì˜ ìŒì•… / í’í–¥Â·í’ì†ë§Œ ì¬ì¶”ì²œ
    if (mode === "music") {
      const segment = body.segment;
      if (!segment) {
        return NextResponse.json(
          { error: "INVALID_INPUT", message: "segment is required for music mode" },
          { status: 400 }
        );
      }

      const llmInput = await prepareLLMInput(
        preprocessed,
        {
          currentMood: {
            id: segment.mood?.id || "",
            name: segment.moodName || segment.mood?.name || "",
            cluster: "0",
            music: {
              genre: segment.musicGenre || segment.music?.genre || "",
              title: segment.music?.title || "",
            },
            scent: {
              type: segment.scentType || segment.scent?.type || "",
              name: segment.scent?.name || "",
            },
            lighting: {
              color: segment.lighting?.color || "#E6F3FF",
              rgb: segment.lighting?.rgb || [230, 243, 255],
            },
          },
          userDataCount: moodStream.userDataCount || 0,
        },
        body.userPreferences
      );

      // "scent" ëª¨ë“œ: í˜„ì¬ ì„¸ê·¸ë¨¼íŠ¸ ì¸ë±ìŠ¤ í¬í•¨
      // bodyì—ì„œ segmentIndexë¥¼ ì§ì ‘ ë°›ê±°ë‚˜, moodStreamì—ì„œ ì°¾ê¸°
      const segmentIndexFromBody = body.segmentIndex;
      const currentSegmentIndex = segmentIndexFromBody !== undefined 
        ? segmentIndexFromBody 
        : (moodStream.moodStream?.findIndex((s: { timestamp: number; duration: number }) => 
            s.timestamp === segment.timestamp && 
            s.duration === segment.duration
          ) ?? -1);
      const cacheKey = {
        moodName: llmInput.moodName,
        musicGenre: llmInput.musicGenre,
        scentType: llmInput.scentType,
        timeOfDay: llmInput.timeOfDay || new Date().getHours(),
        season: llmInput.season || "Winter",
        stressIndex: preprocessed.recent_stress_index,
        segmentIndex: currentSegmentIndex >= 0 ? currentSegmentIndex : undefined,
      };

      const cachedResponse = getCachedResponse(cacheKey);
      if (cachedResponse) {
        return NextResponse.json({ ...cachedResponse, source: "cache" });
      }

      const apiKey = process.env.OPENAI_API_KEY;
      if (!apiKey) {
        console.warn("OPENAI_API_KEY not found, returning minimal mock for music");
        const segment = body.segment;
        const mock: BackgroundParamsResponse = {
          moodAlias: segment?.moodName || segment?.mood?.name || "Calm Breeze",
          musicSelection: segment?.music?.title || segment?.musicTitle || llmInput.moodName,
          moodColor: segment?.lighting?.color || "#E6F3FF",
          lighting: {
            brightness: segment?.lighting?.brightness || 50,
            temperature: segment?.lighting?.temperature || 4000,
          },
          backgroundIcon: segment?.backgroundIcon || {
            name: "FaMusic",
            category: "object",
          },
          backgroundWind: { direction: 180, speed: 3 },
          animationSpeed: segment?.animationSpeed || 5,
          iconOpacity: segment?.iconOpacity || 0.7,
        };
        setCachedResponse(cacheKey, mock);
        return NextResponse.json({ ...mock, source: "mock-no-key" });
      }

      const openai = new OpenAI({ apiKey });

      const prompt = `
      ë‹¹ì‹ ì€ ìŒì•…ê³¼ ë°”ëŒ ì• ë‹ˆë©”ì´ì…˜ì„ ë§¤ì¹­í•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
      ì•„ë˜ ì •ë³´ë¥¼ ë³´ê³ , í˜„ì¬ ë¬´ë“œì™€ ì¥ë¥´ëŠ” ìœ ì§€í•˜ë©´ì„œ ê°™ì€ ì¥ë¥´ ì•ˆì—ì„œ ë‹¤ë¥¸ ëŠë‚Œì˜ ê³¡ ì œëª©ì„ í•˜ë‚˜ ì¶”ì²œí•˜ê³ ,
      ê·¸ ê³¡ì— ì–´ìš¸ë¦¬ëŠ” ë°”ëŒì˜ ë°©í–¥ê³¼ ì†ë„ë¥¼ ì¶”ì²œí•˜ì„¸ìš”.

      [ë¬´ë“œ]: ${llmInput.moodName}
      [ìŒì•… ì¥ë¥´]: ${llmInput.musicGenre}
      [í˜„ì¬ ê³¡]: ${segment.music?.title || segment.musicTitle || ""}
      [ìŠ¤íŠ¸ë ˆìŠ¤]: í‰ê·  ${preprocessed.average_stress_index}, ìµœê·¼ ${preprocessed.recent_stress_index}

      ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
      {
        "musicSelection": "ìƒˆ ê³¡ ì œëª© (ì˜ˆ: Calm Ocean Breath)",
        "backgroundWind": {
          "direction": 0-360 (ìˆ«ì),
          "speed": 0-10 (ìˆ«ì, 0ì€ ì •ì§€, 10ì€ ë§¤ìš° ë¹ ë¦„)
        }
      }
      `;

      const completion = await openai.chat.completions.create({
        model: "gpt-4o-mini",
        messages: [
          { role: "system", content: "JSONë§Œ ì‘ë‹µ" },
          { role: "user", content: prompt },
        ],
        response_format: { type: "json_object" },
        temperature: 0.7,
        max_tokens: 200,
      });

      const raw = JSON.parse(completion.choices[0].message.content || "{}");
      
      // ê¸°ì¡´ ì„¸ê·¸ë¨¼íŠ¸ ê°’ìœ¼ë¡œ ì™„ì „í•œ BackgroundParamsResponse êµ¬ì„±
      const result: BackgroundParamsResponse = {
        moodAlias: segment.moodName || segment.mood?.name || "Calm Breeze",
        musicSelection: raw.musicSelection || segment.music?.title || segment.musicTitle || llmInput.moodName,
        moodColor: segment.lighting?.color || "#E6F3FF",
        lighting: {
          brightness: segment.lighting?.brightness || 50,
          temperature: segment.lighting?.temperature || 4000,
        },
        backgroundIcon: segment.backgroundIcon || {
          name: "FaMusic",
          category: "object",
        },
        backgroundWind: raw.backgroundWind || { direction: 180, speed: 3 },
        animationSpeed: segment.animationSpeed || 5,
        iconOpacity: segment.iconOpacity || 0.7,
      };
      
      setCachedResponse(cacheKey, result);
      return NextResponse.json({ ...result, source: "openai" });
    }

    // ë°©ì–´ ì½”ë“œ (ì´ê³³ì— ë„ë‹¬í•˜ì§€ ì•Šì•„ì•¼ í•¨)
    return NextResponse.json(getMockResponse());
  } catch (error) {
    console.error("Background params generation error:", error);
    
    // ì—ëŸ¬ ë°œìƒ ì‹œ ëª©ì—… ì‘ë‹µ ë°˜í™˜ (ì„œë¹„ìŠ¤ ì¤‘ë‹¨ ë°©ì§€)
    return NextResponse.json(getMockResponse());
  }
}

/**
 * [MOCK] ëª©ì—… ì‘ë‹µ (OpenAI API ì‹¤íŒ¨ ì‹œ fallback)
 * UI FLOW í™•ì¸ì„ ìœ„í•´ ë³´ì¡´
 * TODO: DB ì—°ê²° ì‹¤íŒ¨ ì‹œ ìë™ìœ¼ë¡œ ì´ í•¨ìˆ˜ í˜¸ì¶œí•˜ë„ë¡ ê°œì„  ê°€ëŠ¥
 */
function getMockResponse() {
  return {
    moodAlias: "ê²¨ìš¸ë¹„ì˜ í‰ì˜¨",
    musicSelection: "Ambient Rain Meditation",
    moodColor: "#6B8E9F",
    lighting: {
      brightness: 50,
      temperature: 4000,
    },
    backgroundIcon: {
      name: "FaCloudRain",
      category: "weather",
    },
    backgroundWind: {
      direction: 180,
      speed: 3,
    },
    animationSpeed: 4,
    iconOpacity: 0.7,
    iconCount: 8,
    iconSize: 50,
    particleEffect: false,
    gradientColors: ["#6B8E9F", "#87CEEB"],
    source: "mock" as const,
  };
}

