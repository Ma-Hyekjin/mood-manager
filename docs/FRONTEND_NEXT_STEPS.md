# 프론트엔드 다음 단계 가이드

**작성일**: 2025년  
**목적**: 프론트엔드 완료 후 해야 할 일 및 다음 파트 추천

---

## ✅ 현재 프론트엔드 완료 상태

### 완료된 작업
- ✅ 모든 페이지 구현 (로그인, 회원가입, 비밀번호 찾기, 홈, 마이페이지)
- ✅ 컴포넌트 분리 완료 (모든 페이지 300라인 이하)
- ✅ API Routes 구현 완료 (21개 엔드포인트, 목업 모드)
- ✅ Toast Notification, Error Boundary 적용
- ✅ 로딩 스켈레톤 UI 추가
- ✅ 디바이스 관리 시스템 (추가, 삭제, 전원 제어, 이름 변경)
- ✅ 무드 관리 시스템 (전체 변경, 향 변경, 노래 변경, 색상 변경)
- ✅ 반응형 디자인 (375px 기준)
- ✅ 디자인 시스템 가이드 완료
- ✅ 무드 대시보드 개선 (무드 지속 시간 표시, 간트 차트 스타일 진행 바)
- ✅ 무드셋 저장 기능 (하트 아이콘, UI만 구현)
- ✅ 디바이스 카드 확장 기능 (조명 RGB 컬러 피커 + 밝기 슬라이더, 향 분사량 슬라이더)

### 준비 완료 사항
- ✅ API 명세서 완료 (`docs/API_SPEC.md`)
- ✅ 모든 API Route 코드 준비됨 (주석 처리)
- ✅ 에러 처리 로직 포함
- ✅ 목업 모드로 모든 기능 테스트 완료

---

## 🎯 프론트엔드에서 해야 할 일

### 1. 백엔드 연동 대기 중 ⏳

**현재 상태**: 백엔드 담당자가 API 구현 중

**준비 완료 사항**:
- ✅ API 명세서 완료 (`docs/API_SPEC.md`)
- ✅ 모든 API Route 코드 준비됨 (주석 처리)
- ✅ 에러 처리 로직 포함
- ✅ 목업 모드로 모든 기능 테스트 완료

**백엔드 담당자에게 전달할 사항**:
- API 명세서 참고 (`docs/API_SPEC.md`)
- 요청/응답 형식 정확히 일치 필요
- CORS 설정 필요
- 인증 방식 확인 (NextAuth 세션)

---

### 2. 백엔드 연동 시 작업 순서

#### 2.1 환경 설정
```bash
# .env.local 파일에 추가
NEXT_PUBLIC_BACKEND_URL=http://localhost:8000
# 또는
BACKEND_URL=http://localhost:8000
```

#### 2.2 API Routes 주석 해제
각 API Route 파일에서:
1. 목업 응답 코드 주석 처리
2. 실제 백엔드 호출 코드 주석 해제
3. 테스트

**주요 파일**:
- `src/app/api/auth/**/route.ts` (인증 관련)
- `src/app/api/devices/**/route.ts` (디바이스 관리)
- `src/app/api/moods/**/route.ts` (무드 관리)
- `src/app/api/inquiry/route.ts` (1:1 문의)

#### 2.3 단계별 테스트
1. **인증 API** 먼저 테스트
   - 로그인/회원가입
   - 세션 관리 확인
   - 소셜 로그인 (Google, Kakao, Naver)
2. **디바이스 API** 테스트
   - 목록 조회
   - 생성/삭제
   - 전원 제어
   - 이름 변경
3. **무드 API** 테스트
   - 현재 무드 조회
   - 무드 변경 (전체, 향, 노래, 색상)
4. **통합 테스트**
   - 전체 플로우
   - 에러 케이스
   - 성능 확인

---

### 3. 백엔드 연동 후 작업

#### 필수 작업
- [ ] API 연동 테스트
- [ ] 에러 케이스 처리 확인
- [ ] 성능 확인
- [ ] 버그 수정
- [ ] 실제 데이터로 UI 테스트
- [ ] 무드셋 저장 기능 백엔드 연동
- [ ] 디바이스 컨트롤 기능 백엔드 연동 (조명 컬러/밝기, 향 분사량)
- [ ] 무드 지속 시간 관리 백엔드 연동
  - 무드 지속 시간 조회 API
  - 무드 새로고침 API (클러스터 내 변경)
  - 무드 생명주기 관리 (백엔드 스케줄러)

#### 선택 작업 (성능/UX 개선)
- [ ] 실시간 업데이트 (WebSocket/SSE)
- [ ] 캐싱 전략 (React Query/SWR)
- [ ] 성능 최적화
- [ ] 무한 스크롤 (무드 히스토리 등)
- [ ] 오프라인 지원 (Service Worker)
- [ ] 무드 라이브러리 페이지 구현 (`/mood`)
  - 무드 히스토리 목록 (최근 20개)
  - 저장된 무드셋 목록
  - 무드 카테고리별 필터링
  - 무드 상세 정보 및 적용 버튼

---

## 🔄 다음 파트 추천

### 추천 순서

#### 1순위: 백엔드 API 연동 ⭐⭐⭐

**이유**:
- 프론트엔드와 가장 밀접하게 연관됨
- API 명세서가 이미 완료되어 있어 바로 시작 가능
- 목업 코드가 준비되어 있어 주석 해제만 하면 됨
- 프론트엔드 개발자가 백엔드 API를 테스트하면서 문제를 빠르게 발견 가능

**작업 내용**:
- Next.js API Routes에서 실제 백엔드 서버로 요청 전달
- 인증 처리 (NextAuth 세션 → 백엔드 인증)
- 에러 처리 및 응답 변환
- 프론트엔드와 백엔드 간 데이터 형식 일치 확인

**예상 시간**: 1-2주

---

#### 2순위: 무드 추론 엔진 (Mood Inference Engine) ⭐⭐

**이름 설명**:
- **공식 명칭**: "Mood Inference Engine" 또는 "Mood Inference System"
- **한국어**: "무드 추론 엔진" 또는 "무드 추론 시스템"
- **다른 용어**: "Mood Analysis Engine", "Mood Prediction System"
- **역할**: 생체 데이터, 오디오 이벤트, 사용자 선호도, 날씨 등을 종합하여 무드 패턴을 결정하고 속성(음악, 향, 조명)을 결정하는 시스템

**이유**:
- 프론트엔드에서 데이터 흐름을 이해하고 있음
- `docs/MOOD_SYSTEM_ARCHITECTURE.md` 문서가 완성되어 있어 바로 시작 가능
- 프론트엔드 개발자가 UI와 연동하면서 테스트 가능
- 백엔드 API가 준비되면 바로 통합 가능

**작업 내용**:
- Firebase에서 생체 데이터 및 ML 분류 결과 읽기
- 데이터 전처리 (스트레스 지수, 수면 상태 계산)
- 무드 패턴 결정 로직 구현 (MOOD_PATTERNS 선택)
- 속성 결정 로직 구현 (음악, 향, 조명 매핑)
- OpenAI API 연동 (무드 이름 생성)
- DB 저장 (MoodCycle)

**예상 시간**: 2-3주

**참고 문서**: `docs/MOOD_SYSTEM_ARCHITECTURE.md`

---

#### 3순위: ML 서버 연동 ⭐

**이유**:
- ML 서버는 독립적으로 동작 가능
- 백엔드나 무드 추론 엔진이 준비되면 통합 가능
- 프론트엔드 개발자가 직접 작업하기보다는 ML 담당자와 협업

**작업 내용**:
- ML 서버에서 Firestore의 오디오 이벤트 읽기
- 오디오 분류 (웃음/한숨/소음)
- 분류 결과를 Firestore 또는 백엔드로 전송
- 프론트엔드/백엔드에서 ML 결과 수신

**예상 시간**: 1-2주 (ML 모델 학습 포함 시 더 길어질 수 있음)

---

## 📊 전체 파이프라인 이해

### 현재 파이프라인
```
WearOS → Firebase → ML 서버 → 백엔드 → 무드 추론 엔진 → OpenAI → 프론트엔드
```

### 각 파트의 역할

1. **WearOS** (완료)
   - 생체 데이터 수집
   - 오디오 이벤트 수집
   - Firestore로 전송

2. **Firebase** (완료)
   - 데이터 저장소
   - 실시간 동기화

3. **ML 서버** (Python, 미구현)
   - 오디오 분류 (웃음/한숨)
   - 분류 결과 반환

4. **백엔드 API** (미구현)
   - 인증 처리
   - 디바이스 관리
   - 무드 관리
   - 데이터베이스 관리

5. **무드 추론 엔진** (미구현)
   - 데이터 전처리
   - 무드 패턴 결정
   - 속성 결정 (음악, 향, 조명)
   - OpenAI 연동

6. **프론트엔드** (완료)
   - UI 표시
   - 사용자 인터랙션
   - 백엔드 API 호출

---

## 🎯 추천 작업 순서

### 단계 1: 백엔드 API 연동 (1-2주)
- 프론트엔드와 백엔드 간 통신 확인
- 실제 데이터로 UI 테스트
- 버그 수정 및 성능 최적화

### 단계 2: 무드 추론 엔진 구현 (2-3주)
- 데이터 전처리 로직 구현
- 무드 패턴 결정 로직 구현
- 속성 결정 로직 구현 (매핑 테이블)
- OpenAI 연동
- DB 저장

### 단계 3: ML 서버 연동 (1-2주)
- ML 서버와 Firestore 연동
- 분류 결과 수신 및 처리
- 무드 추론 엔진에 통합

### 단계 4: 통합 테스트 (1주)
- 전체 파이프라인 테스트
- End-to-End 테스트
- 성능 최적화
- 버그 수정

---

## 📝 참고 문서

- `docs/API_SPEC.md` - API 명세서
- `docs/API_ROUTES.md` - API Routes 구조
- `docs/MOOD_SYSTEM_ARCHITECTURE.md` - 무드 시스템 아키텍처 가이드
- `docs/MOOD_DURATION_API_DESIGN.md` - 무드 지속 시간 API 설계
- `docs/TODO.md` - 전체 TODO 리스트
- `docs/PAGE_ROLES.md` - 페이지별 역할 및 구현 상태

---

## 💡 팁

### 백엔드 연동 시
- 단계별로 테스트 (인증 → 디바이스 → 무드)
- 에러 케이스 먼저 확인
- 실제 데이터로 UI 테스트

### 무드 추론 엔진 구현 시
- `docs/MOOD_SYSTEM_ARCHITECTURE.md`의 옵션 3 (규칙 + 우선순위) 추천
- 초기 매핑 규칙을 팀과 논의하여 결정
- OpenAI 프롬프트는 반복적으로 개선

### ML 서버 연동 시
- ML 담당자와 협업
- 분류 결과 형식 명확히 정의
- 에러 처리 (분류 실패 시 기본값)

